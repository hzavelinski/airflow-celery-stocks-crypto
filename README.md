# Projeto de Pipelines de Dados com Airflow e Celery

Este projeto demonstra a construÃ§Ã£o de pipelines de dados utilizando Apache Airflow e Celery para orquestraÃ§Ã£o e agendamento de tarefas. O objetivo Ã© coletar, processar e salvar cotaÃ§Ãµes diÃ¡rias de aÃ§Ãµes e criptomoedas em formato CSV localmente.

## ğŸ“ VisÃ£o Geral do Projeto

### Objetivos
1. **Coletar Dados:** Extrair cotaÃ§Ãµes diÃ¡rias de aÃ§Ãµes e criptomoedas de APIs pÃºblicas e salvar localmente em formato CSV.
2. **Processar e Armazenar:** Transformar os dados e salvÃ¡-los localmente em formato CSV.

## ğŸ› ï¸ Tecnologias Utilizadas
* **Apache Airflow:** Para orquestraÃ§Ã£o e agendamento de tarefas.
* **Celery:** Para gerenciamento de tarefas assÃ­ncronas no Airflow.

## ğŸ—ï¸ Arquitetura do Pipeline
* **ExtraÃ§Ã£o:** Uma tarefa no Airflow coleta cotaÃ§Ãµes diÃ¡rias de aÃ§Ãµes e criptomoedas das APIs pÃºblicas.
* **TransformaÃ§Ã£o:** Os dados brutos extraÃ­dos sÃ£o processados e transformados em formato CSV.
* **Armazenamento:** Os dados transformados sÃ£o armazenados localmente nas pastas `data/stocks` e `data/crypto`.


## ğŸ“¥ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

1. **Configurar o Apache Airflow com Celery:**
   - Instale o Apache Airflow e Celery.
   - Configure o `airflow.cfg` para usar o Celery como executor.

2. **Instalar DependÃªncias:**
   - Instale as dependÃªncias necessÃ¡rias para o Airflow.

3. **Executar o Pipeline:**
   - Inicie o servidor do Airflow e o worker do Celery.
   - Execute os DAGs para iniciar o processo de coleta e transformaÃ§Ã£o de dados.


## ğŸ”— ReferÃªncias

* [DocumentaÃ§Ã£o do Apache Airflow](https://airflow.apache.org/)
* [DocumentaÃ§Ã£o do Celery](https://docs.celeryproject.org/)


